import pandas as pd
import base64
import io
from typing import Tuple, List, Dict, Optional
from config import logger, next_shift_id, EMOJI_MAPPING, ICON_CONFIG
from error_handler import ErrorHandler
import dash_leaflet as dl
from dash import html
import json

class DataProcessor:
    @staticmethod
    def load_excel_file(contents: str, filename: str) -> Tuple[Optional[pd.DataFrame], Optional[str]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç Excel-—Ñ–∞–π–ª.

        Args:
            contents: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ base64.
            filename: –ò–º—è —Ñ–∞–π–ª–∞.

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (DataFrame, –æ—à–∏–±–∫–∞). –ï—Å–ª–∏ –æ—à–∏–±–∫–∞, DataFrame=None.
        """
        try:
            logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {filename}")
            content_type, content_string = contents.split(',')
            decoded = base64.b64decode(content_string)
            
            if filename.endswith('.xlsx'):
                df = pd.read_excel(io.BytesIO(decoded), engine='openpyxl')
            elif filename.endswith('.xls'):
                df = pd.read_excel(io.BytesIO(decoded), engine='xlrd')
            else:
                error = "–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ .xlsx –∏–ª–∏ .xls."
                logger.error(error)
                return None, error

            df['row_id'] = range(len(df))
            return ErrorHandler.validate_excel_file(df, filename)
        except Exception as e:
            return None, ErrorHandler.handle_exception(e, "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")

    @staticmethod
    def filter_data(data: List[Dict], search_value: str) -> List[Dict]:
        """
        –§–∏–ª—å—Ç—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ —Å—Ç—Ä–æ–∫–µ –ø–æ–∏—Å–∫–∞.

        Args:
            data: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü—ã.
            search_value: –°—Ç—Ä–æ–∫–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞.

        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π.
        """
        logger.info(f"–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ–∏—Å–∫ —Å –∑–∞–ø—Ä–æ—Å–æ–º: {search_value}")
        if not search_value:
            logger.info("–ü–æ–∏—Å–∫ —Å–±—Ä–æ—à–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–µ–Ω—ã –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.")
            return data
        df = pd.DataFrame(data)
        mask = df.apply(lambda row: row.astype(str).str.contains(search_value, case=False).any(), axis=1)
        filtered_data = df[mask].to_dict("records")
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(filtered_data)} —Å—Ç—Ä–æ–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É.")
        return filtered_data

    @staticmethod
    def transfer_rows(data_store: List[Dict], turn_store: List[Dict], grid_selected_rows: List[Dict], shift_id: int) -> Tuple[List[Dict], List[Dict], List[Dict]]:
        """
        –ü–µ—Ä–µ–Ω–æ—Å–∏—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ data_store –≤ turn_store –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å–º–µ–Ω—ã.

        Args:
            data_store: –î–∞–Ω–Ω—ã–µ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã.
            turn_store: –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã Turn.
            grid_selected_rows: –í—ã–±—Ä–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã.
            shift_id: ID —Å–º–µ–Ω—ã.

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–Ω–æ–≤—ã–π data_store, –Ω–æ–≤—ã–π turn_store, –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è turn-grid).
        """
        logger.info("–ü–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü—É Turn.")
        selected_row_ids = {row["row_id"] for row in grid_selected_rows}
        new_data_store = [row for row in data_store if row["row_id"] not in selected_row_ids]
        new_turn_store = turn_store.copy()
        updated_rows = []
        for shift in new_turn_store:
            if shift["shift_id"] == shift_id:
                shift["rows"] = shift["rows"] + grid_selected_rows
                updated_rows = shift["rows"]
                break
        logger.info(f"–ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ {len(grid_selected_rows)} —Å—Ç—Ä–æ–∫ –≤ —Å–º–µ–Ω—É {shift_id}.")
        return new_data_store, new_turn_store, updated_rows

    @staticmethod
    def update_shift(shift_store: List[Dict], cell_changed: Dict) -> Tuple[List[Dict], str]:
        """
        –û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å–º–µ–Ω—ã –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —è—á–µ–π–∫–∏ –≤ shift-grid.

        Args:
            shift_store: –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Å–º–µ–Ω.
            cell_changed: –î–∞–Ω–Ω—ã–µ –æ–± –∏–∑–º–µ–Ω—ë–Ω–Ω–æ–π —è—á–µ–π–∫–µ.

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–Ω–æ–≤—ã–π shift_store, —Å–æ–æ–±—â–µ–Ω–∏–µ).
        """
        logger.info("–ò–∑–º–µ–Ω–µ–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ shift-grid.")
        logger.debug(f"cell_changed raw: {cell_changed}")
        if not cell_changed:
            logger.warning("–î–∞–Ω–Ω—ã–µ cell_changed –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
            return shift_store, "–î–∞–Ω–Ω—ã–µ –æ–± –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç."

        cell_data = cell_changed[0] if isinstance(cell_changed, list) else cell_changed

        try:
            shift_id = cell_data["rowId"]
            field = cell_data["colId"]
            new_value = cell_data.get("newValue", cell_data.get("value", ""))
        except (KeyError, TypeError) as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ cell_changed: {e}, cell_changed: {cell_changed}")
            return shift_store, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å–º–µ–Ω—ã: –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö."

        new_shift_store = shift_store.copy()
        for shift in new_shift_store:
            if str(shift["shift_id"]) == str(shift_id):
                shift[field] = new_value
                logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–ª–µ {field} –¥–ª—è —Å–º–µ–Ω—ã {shift_id}.")
                logger.debug(f"new_shift_store after update: {new_shift_store}")
                return new_shift_store, f"–û–±–Ω–æ–≤–ª–µ–Ω–∞ —Å–º–µ–Ω–∞ {shift_id}."
        
        logger.warning(f"–°–º–µ–Ω–∞ —Å shift_id={shift_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ shift_store.")
        return shift_store, f"–°–º–µ–Ω–∞ {shift_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."

    @staticmethod
    def create_shift(shift_store: List[Dict], turn_store: List[Dict]) -> Tuple[List[Dict], List[Dict], str]:
        """
        –°–æ–∑–¥–∞—ë—Ç –Ω–æ–≤—É—é —Å–º–µ–Ω—É –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç shift_store –∏ turn_store.

        Args:
            shift_store: –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã —Å–º–µ–Ω.
            turn_store: –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã Turn.

        Returns:
            –ö–æ—Ä—Ç–µ–∂ (–Ω–æ–≤—ã–π shift_store, –Ω–æ–≤—ã–π turn_store, —Å–æ–æ–±—â–µ–Ω–∏–µ).
        """
        logger.info("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Å–º–µ–Ω—ã.")
        logger.debug(f"shift_store before adding: {shift_store}")

        current_max_id = max([shift["shift_id"] for shift in shift_store], default=next_shift_id-1) if shift_store else next_shift_id-1
        new_shift_id = current_max_id + 1

        new_shift = {
            "shift_id": new_shift_id,
            "max_ts": 38,
            "col_pal": 0.0,
            "col_kg": 0.00,
            "head": "",
            "trailer": "",
            "comments": ""
        }

        new_shift_store = shift_store + [new_shift]
        new_turn_store = turn_store + [{"shift_id": new_shift_id, "rows": []}]

        logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è —Å–º–µ–Ω–∞ —Å shift_id={new_shift_id}.")
        logger.debug(f"new_shift: {new_shift}")
        logger.debug(f"shift_store after adding: {new_shift_store}")
        return new_shift_store, new_turn_store, f"–°–æ–∑–¥–∞–Ω–∞ —Å–º–µ–Ω–∞ {new_shift_id}."

    @staticmethod
    def prepare_map_data(table_row_data):
        """
        –§–æ—Ä–º–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞—Ä—Ç—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü—ã order-grid.
        
        Args:
            table_row_data: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü—ã.
        
        Returns:
            pandas.DataFrame —Å —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∫–∞—Ä—Ç—ã.
        """
        required_columns = ['contact_code', '–®–∏—Ä–æ—Ç–∞', '–î–æ–ª–≥–æ—Ç–∞', '–ê–¥—Ä–µ—Å', '–ù–∞—Å–µ–ª—ë–Ω–Ω—ã–π_–ø—É–Ω–∫—Ç', '–¢–∏–ø_–¢–°', '–ó–∞–∫–∞–∑', '–¢–æ–≤–∞—Ä', '–ü–∞–ª', '–ö–ì']
        try:
            logger.debug(f"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—Ä—Ç—ã: {len(table_row_data)} –∑–∞–ø–∏—Å–µ–π")
            table_df = pd.DataFrame(table_row_data)
            if table_df.empty:
                logger.info("–î–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞—Ä—Ç—ã –ø—É—Å—Ç—ã.")
                return pd.DataFrame(columns=required_columns)

            available_cols = table_df.columns.tolist()
            logger.debug(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã: {available_cols}")
            missing_cols = [col for col in required_columns if col not in table_df.columns]
            if missing_cols:
                logger.error(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {missing_cols}")
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Ç–æ–ª–±—Ü—ã: {missing_cols}")

            grouped_data = table_df.groupby('contact_code').agg({
                '–®–∏—Ä–æ—Ç–∞': 'first',
                '–î–æ–ª–≥–æ—Ç–∞': 'first',
                '–ê–¥—Ä–µ—Å': 'first',
                '–ù–∞—Å–µ–ª—ë–Ω–Ω—ã–π_–ø—É–Ω–∫—Ç': 'first',
                '–¢–∏–ø_–¢–°': 'first',
                '–ó–∞–∫–∞–∑': list,
                '–¢–æ–≤–∞—Ä': list,
                '–ü–∞–ª': list,
                '–ö–ì': list
            }).reset_index()
            logger.debug(f"–°–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–æ {len(grouped_data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∫–∞—Ä—Ç—ã")
            return grouped_data
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–∞—Ä—Ç—ã: {str(e)}")
            raise

    @staticmethod
    def create_popup_content(row):
        """
        –°–æ–∑–¥–∞—ë—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤—Å–ø–ª—ã–≤–∞—é—â–µ–≥–æ –æ–∫–Ω–∞ –¥–ª—è –º–∞—Ä–∫–µ—Ä–∞.
        
        Args:
            row: –°—Ç—Ä–æ–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ—á–∫–∏ (–∏–∑ grouped_data).
        
        Returns:
            dash.html.Div —Å —Ç–∞–±–ª–∏—Ü–µ–π —Ç–æ–≤–∞—Ä–æ–≤.
        """
        table_rows = []
        for product, pal, kg in zip(row['–¢–æ–≤–∞—Ä'], row['–ü–∞–ª'], row['–ö–ì']):
            emoji = EMOJI_MAPPING.get(product.split()[-1].lower() if isinstance(product, str) else "", "")
            table_rows.append(html.Tr([html.Td(f"{emoji} {product}"), html.Td(pal), html.Td(kg)]))
        table_rows.append(html.Tr([
            html.Td("–°—É–º–º–∞"),
            html.Td(round(sum(row['–ü–∞–ª']), 2)),
            html.Td(round(sum(row['–ö–ì']), 2))
        ]))
        return html.Div([
            html.Table([
                html.Thead(html.Tr([html.Th("–¢–æ–≤–∞—Ä"), html.Th("–ü–∞–ª"), html.Th("–ö–ì")])),
                html.Tbody(table_rows)
            ])
        ])

    @staticmethod
    def create_marker(row):
        """
        –°–æ–∑–¥–∞—ë—Ç –º–∞—Ä–∫–µ—Ä –∏ –ø–æ–¥–ø–∏—Å—å –¥–ª—è —Ç–æ—á–∫–∏ –Ω–∞ –∫–∞—Ä—Ç–µ.
        
        Args:
            row: –°—Ç—Ä–æ–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ—á–∫–∏ (–∏–∑ grouped_data).
        
        Returns:
            dash_leaflet.LayerGroup —Å –º–∞—Ä–∫–µ—Ä–æ–º –∏ –ø–æ–¥–ø–∏—Å—å—é.
        """
        icon_key = row['–¢–∏–ø_–¢–°']
        popup_content = DataProcessor.create_popup_content(row)
        tooltip_text = f"{row['–ù–∞—Å–µ–ª—ë–Ω–Ω—ã–π_–ø—É–Ω–∫—Ç']}\n{row['–ê–¥—Ä–µ—Å']}"
        lat, lon = row['–®–∏—Ä–æ—Ç–∞'], row['–î–æ–ª–≥–æ—Ç–∞']

        default_icon = {
            "iconUrl": "https://unpkg.com/leaflet@1.7.1/dist/images/marker-icon.png",
            "iconSize": [25, 41],
            "iconAnchor": [12.5, 41]
        }

        if icon_key == 'islands#graySportIcon':
            icon_html = (
                f'<svg width="30" height="41" viewBox="0 0 30 41" xmlns="http://www.w3.org/2000/svg">'
                f'<path d="M15 0C6.716 0 0 6.716 0 15c0 10.5 15 26 15 26s15-15.5 15-26C30 6.716 23.284 0 15 0z" fill="#808080"/>'
                f'<text x="15" y="20" font-size="12" fill="#FFFFFF" text-anchor="middle" font-family="Arial">üîó</text>'
                f'</svg>'
            )
            marker = dl.Marker(
                position=[lat, lon],
                icon={
                    "iconUrl": f"data:image/svg+xml;base64,{base64.b64encode(icon_html.encode()).decode()}",
                    "iconSize": [30, 41],
                    "iconAnchor": [15, 41]
                },
                children=[dl.Popup(popup_content)]
            )
            label_icon_anchor = [-7.5, 40]
        elif icon_key == 'islands#blueSportIcon':
            icon_html = (
                f'<svg width="30" height="41" viewBox="0 0 30 41" xmlns="http://www.w3.org/2000/svg">'
                f'<path d="M15 0C6.716 0 0 6.716 0 15c0 10.5 15 26 15 26s15-15.5 15-26C30 6.716 23.284 0 15 0z" fill="#0000FF"/>'
                f'<text x="15" y="20" font-size="12" fill="#FFFFFF" text-anchor="middle" font-family="Arial">üîó</text>'
                f'</svg>'
            )
            marker = dl.Marker(
                position=[lat, lon],
                icon={
                    "iconUrl": f"data:image/svg+xml;base64,{base64.b64encode(icon_html.encode()).decode()}",
                    "iconSize": [30, 41],
                    "iconAnchor": [15, 41]
                },
                children=[dl.Popup(popup_content)]
            )
            label_icon_anchor = [-7.5, 40]
        else:
            icon_info = ICON_CONFIG.get(icon_key, {})
            icon_url = icon_info.get('normal', default_icon['iconUrl'])
            marker = dl.Marker(
                position=[lat, lon],
                icon={
                    "iconUrl": icon_url,
                    "iconSize": [25, 41],
                    "iconAnchor": [12.5, 41]
                },
                children=[dl.Popup(popup_content)]
            )
            label_icon_anchor = [-5, 40]

        label_html = (
            f'<div style="position: relative; white-space: nowrap; display: inline-block; font-size: 10px; color: black; '
            f'background-color: white; border: 1px solid black; border-radius: 4px; padding: 0.5px 1px; '
            f'line-height: 1.1; top: 0px; left: 0px;">{tooltip_text}</div>'
        )
        label = dl.DivMarker(
            position=[lat, lon],
            iconOptions={
                "html": label_html,
                "iconAnchor": label_icon_anchor
            },
            children=[dl.Popup(popup_content)]
        )
        return dl.LayerGroup(children=[marker, label])